{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 14495532,
     "sourceType": "datasetVersion",
     "datasetId": 9220946
    }
   ],
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Setup"
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "def check_env() -> str:\n",
    "    if os.environ.get('KAGGLE_KERNEL_RUN_TYPE'):\n",
    "        print(\"Running on Kaggle\")\n",
    "        return \"kaggle\"\n",
    "    else:\n",
    "        print(\"Running locally\")\n",
    "        return \"local\"\n",
    "\n",
    "\n",
    "ENV = check_env()\n",
    "\n",
    "if ENV == \"kaggle\":\n",
    "    data_dir = Path(\"/kaggle/input/ka-ocr\")\n",
    "else:\n",
    "    load_dotenv()\n",
    "\n",
    "    from huggingface_hub import hf_hub_download\n",
    "\n",
    "    data_dir = Path(\"./data\")\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    hf_repo = os.getenv(\"HF_DATASET_REPO\")\n",
    "    hf_token = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "    if not hf_repo:\n",
    "        raise ValueError(\"HF_DATASET_REPO not set in .env\")\n",
    "\n",
    "    # Download with automatic caching - skips if local matches remote (etag-based)\n",
    "    zip_path = hf_hub_download(\n",
    "        repo_id=hf_repo,\n",
    "        filename=\"ka-ocr.zip\",\n",
    "        repo_type=\"dataset\",\n",
    "        token=hf_token,\n",
    "        local_dir=data_dir,\n",
    "    )\n",
    "\n",
    "    # Extract only if not already extracted OR if zip is newer than extraction\n",
    "    extract_marker = data_dir / \".extracted\"\n",
    "    zip_file = Path(zip_path)\n",
    "    needs_extract = (\n",
    "        not extract_marker.exists() or\n",
    "        zip_file.stat().st_mtime > extract_marker.stat().st_mtime\n",
    "    )\n",
    "\n",
    "    if needs_extract:\n",
    "        print(\"Extracting dataset...\")\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(data_dir)\n",
    "        extract_marker.touch()\n",
    "        print(\"Extraction complete\")\n",
    "    else:\n",
    "        print(\"Dataset already extracted, skipping\")\n",
    "\n",
    "print(f\"\\nDataset contents in {data_dir}:\")\n",
    "for item in data_dir.iterdir():\n",
    "    if not item.name.startswith('.') and item.name != \"ka-ocr.zip\":\n",
    "        print(f\"  {item.name}\")"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-18T11:24:11.010653Z",
     "iopub.execute_input": "2026-01-18T11:24:11.010974Z",
     "iopub.status.idle": "2026-01-18T11:24:11.019009Z",
     "shell.execute_reply.started": "2026-01-18T11:24:11.010948Z",
     "shell.execute_reply": "2026-01-18T11:24:11.018087Z"
    },
    "ExecuteTime": {
     "end_time": "2026-01-19T06:03:36.545095Z",
     "start_time": "2026-01-19T06:03:34.183549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Mega\\Python\\Ka-OCR\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already extracted, skipping\n",
      "\n",
      "Dataset contents in data:\n",
      "  3d_unicode\n",
      "  alkroundedmtav-medium\n",
      "  alkroundednusx-medium\n",
      "  ar-archy-regular\n",
      "  arial_geo\n",
      "  arial_geo-bold\n",
      "  arial_geo-bold-italic\n",
      "  arial_geo-italic\n",
      "  bpg_algeti\n",
      "  bpg_algeti_compact\n",
      "  bpg_arial_2009\n",
      "  bpg_boxo\n",
      "  bpg_boxo-boxo\n",
      "  bpg_classic_medium\n",
      "  bpg_dedaena\n",
      "  bpg_dedaena_nonblock\n",
      "  bpg_excelsior_caps_dejavu_2010\n",
      "  bpg_excelsior_dejavu_2010\n",
      "  bpg_extrasquare_2009\n",
      "  bpg_extrasquare_mtavruli_2009\n",
      "  bpg_glaho\n",
      "  bpg_glaho_2008\n",
      "  bpg_glaho_arial\n",
      "  bpg_glaho_bold\n",
      "  bpg_glaho_sylfaen\n",
      "  bpg_glaho_traditional\n",
      "  bpg_ingiri_2008\n",
      "  bpg_irubaqidze\n",
      "  bpg_mrgvlovani_caps_2010\n",
      "  bpg_nino_elite_exp\n",
      "  bpg_nino_elite_ultra\n",
      "  bpg_nino_elite_ultra_caps\n",
      "  bpg_nino_medium_caps\n",
      "  bpg_nino_mtavruli_bold\n",
      "  bpg_nino_mtavruli_book\n",
      "  bpg_nino_mtavruli_normal\n",
      "  bpg_no9\n",
      "  bpg_nostalgia\n",
      "  bpg_paata\n",
      "  bpg_paata_caps\n",
      "  bpg_paata_cond\n",
      "  bpg_paata_cond_caps\n",
      "  bpg_paata_exp\n",
      "  bpg_phone_sans_bold\n",
      "  bpg_phone_sans_bold_italic\n",
      "  bpg_phone_sans_italic\n",
      "  bpg_quadrosquare_2009\n",
      "  bpg_rioni\n",
      "  bpg_rioni_contrast\n",
      "  bpg_rioni_vera\n",
      "  bpg_sans_2008\n",
      "  bpg_serif_2008\n",
      "  bpg_square_2009\n",
      "  bpg_supersquare_2009\n",
      "  bpg_ucnobi\n",
      "  bpg_venuri_2010\n",
      "  fixedsys_excelsior\n",
      "  gf_aisi_nus-bold-italic\n",
      "  gf_aisi_nus_medium-medium-italic\n",
      "  gugeshashvili_slfn_2\n",
      "  ka_literaturuli\n",
      "  ka_lortkipanidze\n",
      "  literaturulitt\n",
      "  metadata.csv\n",
      "  mg_bitneon\n",
      "  mg_bitneon_chaos\n",
      "  mg_niniko\n",
      "  NotoSansGeorgian\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Explore data"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T06:03:41.929686Z",
     "start_time": "2026-01-19T06:03:36.602450Z"
    }
   },
   "cell_type": "code",
   "source": "import pandas as pd",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T06:04:58.699762Z",
     "start_time": "2026-01-19T06:04:58.535623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(data_dir/\"metadata.csv\")\n",
    "print(df.head())\n",
    "print(df.tail())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        file_name          text\n",
      "0  3d_unicode/3d_unicode_0000.png          ამათ\n",
      "1  3d_unicode/3d_unicode_0001.png   პარტიანკაში\n",
      "2  3d_unicode/3d_unicode_0002.png  კომენტარების\n",
      "3  3d_unicode/3d_unicode_0003.png       ფრიდრიხ\n",
      "4  3d_unicode/3d_unicode_0004.png   ცდწლოოწნწში\n",
      "                                         file_name      text\n",
      "100495  NotoSansGeorgian/NotoSansGeorgian_1495.png     რიგში\n",
      "100496  NotoSansGeorgian/NotoSansGeorgian_1496.png     ალიკა\n",
      "100497  NotoSansGeorgian/NotoSansGeorgian_1497.png      ტარს\n",
      "100498  NotoSansGeorgian/NotoSansGeorgian_1498.png     კარგი\n",
      "100499  NotoSansGeorgian/NotoSansGeorgian_1499.png  სასახლეს\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T06:03:42.997493Z",
     "start_time": "2026-01-19T06:03:42.933635Z"
    }
   },
   "cell_type": "code",
   "source": "print(df[\"text\"].value_counts())",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text\n",
      "და              4221\n",
      "არ              1163\n",
      "რომ              995\n",
      "იყო              768\n",
      "კი               604\n",
      "                ... \n",
      "ფუფთწჟჯკდპბგ       1\n",
      "ოოწლღდჩქთტტ        1\n",
      "გითქვამს           1\n",
      "სიკვდილია          1\n",
      "ბგშჩდეკშჰ          1\n",
      "Name: count, Length: 38003, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T07:24:34.438927Z",
     "start_time": "2026-01-19T07:24:34.385702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check text length variations\n",
    "df[\"text_len\"] = df[\"text\"].str.len()\n",
    "print(df[\"text_len\"].describe())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    100500.000000\n",
      "mean          6.390886\n",
      "std           2.970310\n",
      "min           2.000000\n",
      "25%           4.000000\n",
      "50%           6.000000\n",
      "75%           8.000000\n",
      "max          24.000000\n",
      "Name: text_len, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Prepare images"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T06:03:43.011465Z",
     "start_time": "2026-01-19T06:03:43.007914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "\n",
    "class GeorgianOCRDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, root_dir: str, processor: object, max_target_length: int = 32):\n",
    "        self.df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.processor = processor\n",
    "        self.max_target_length = max_target_length\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> dict[str, torch.Tensor]:\n",
    "        file_path = f\"{self.root_dir}/{self.df['file_name'][idx]}\"\n",
    "        text = self.df['text'][idx]\n",
    "\n",
    "        # Open and convert to RGB\n",
    "        img = Image.open(file_path).convert(\"RGB\")\n",
    "\n",
    "        # Smart Resize (Letterbox)\n",
    "        w, h = img.size\n",
    "        target_size = 384\n",
    "\n",
    "        # Scale height to target_size, width proportionally\n",
    "        new_w = int(w * (target_size / h))\n",
    "        img = img.resize((new_w, target_size), Image.Resampling.BILINEAR)\n",
    "\n",
    "        if new_w <= target_size:\n",
    "            # Pad the width to make it square\n",
    "            new_img = Image.new(\"RGB\", (target_size, target_size), (255, 255, 255))\n",
    "            offset = ((target_size - new_w) // 2, 0)\n",
    "            new_img.paste(img, offset)\n",
    "        else:\n",
    "            # If still too wide, force resize to square (slight squish)\n",
    "            new_img = img.resize((target_size, target_size), Image.Resampling.BILINEAR)\n",
    "\n",
    "        # Use Processor for Normalization\n",
    "        pixel_values = self.processor(new_img, return_tensors=\"pt\").pixel_values\n",
    "\n",
    "        # Tokenize Georgian Text\n",
    "        labels = self.processor.tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_target_length\n",
    "        ).input_ids\n",
    "\n",
    "        # Replace padding token id with -100 so it's ignored by the loss function\n",
    "        labels = [label if label != self.processor.tokenizer.pad_token_id else -100 for label in labels]\n",
    "\n",
    "        return {\n",
    "            \"pixel_values\": pixel_values.squeeze(),\n",
    "            \"labels\": torch.tensor(labels)\n",
    "        }\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}
